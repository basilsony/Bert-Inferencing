{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Packages\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n"
     ]
    }
   ],
   "source": [
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    print('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________\n",
      "Loading Data...........\n"
     ]
    }
   ],
   "source": [
    "## Loading Dataset\n",
    "print(\"_______________________________________________________________\")\n",
    "print(\"Loading Data...........\")\n",
    "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "data = pd.read_csv(\n",
    "    r\"test.csv\",\n",
    "    header=None,\n",
    "    names=cols,\n",
    "    engine=\"python\",\n",
    "    encoding=\"latin1\"\n",
    ")\n",
    "data.drop([\"id\", \"date\", \"query\", \"user\"],\n",
    "          axis=1,\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = data.sentiment.values\n",
    "data_labels[data_labels == 4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________\n",
      "Data Pre-processing...........\n"
     ]
    }
   ],
   "source": [
    "print(\"_______________________________________________________________\")\n",
    "print(\"Data Pre-processing...........\")\n",
    "def clean_tweet(tweet):\n",
    "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
    "    # Removing the @\n",
    "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
    "    # Removing the URL links\n",
    "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
    "    # Keeping only letters\n",
    "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
    "    # Removing additional whitespaces\n",
    "    tweet = re.sub(r\" +\", ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = [clean_tweet(tweet) for tweet in data.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________\n",
      "Tokenization and Data Preparation...........\n"
     ]
    }
   ],
   "source": [
    "print(\"_______________________________________________________________\")\n",
    "print(\"Tokenization and Data Preparation...........\")\n",
    "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "def encode_sentence(sent):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))\n",
    "\n",
    "# data_inputs = [encode_sentence(sentence) for sentence in data_clean]\n",
    "# data_with_len = [[sent, data_labels[i], len(sent)]\n",
    "#                  for i, sent in enumerate(data_inputs)]\n",
    "# sorted_all = [(sent_lab[0], sent_lab[1])\n",
    "#               for sent_lab in data_with_len if sent_lab[2] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_input_data(data_inputs):\n",
    "    data_with_len = [[sent, 0 , len(sent)]\n",
    "                     for i, sent in enumerate(data_inputs)]\n",
    "    sorted_all = [(sent_lab[0], sent_lab[1])\n",
    "                  for sent_lab in data_with_len if sent_lab[2] > 0]\n",
    "    all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
    "                                                 output_types=(tf.int32, tf.int32))\n",
    "    BATCH_SIZE = 32\n",
    "    all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "    return all_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________\n",
      "Model Building...........\n"
     ]
    }
   ],
   "source": [
    "print(\"_______________________________________________________________\")\n",
    "print(\"Model Building...........\")\n",
    "class DCNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 emb_dim=128,\n",
    "                 nb_filters=50,\n",
    "                 FFN_units=512,\n",
    "                 nb_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"dcnn\"):\n",
    "        super(DCNN, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size,\n",
    "                                          emb_dim)\n",
    "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
    "                                    kernel_size=2,\n",
    "                                    padding=\"valid\",\n",
    "                                    activation=\"relu\")\n",
    "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
    "                                     kernel_size=3,\n",
    "                                     padding=\"valid\",\n",
    "                                     activation=\"relu\")\n",
    "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
    "                                      kernel_size=4,\n",
    "                                      padding=\"valid\",\n",
    "                                      activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D()\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if nb_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=nb_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        x_1 = self.bigram(x) # batch_size, nb_filters, seq_len-1)\n",
    "        x_1 = self.pool(x_1) # (batch_size, nb_filters)\n",
    "        x_2 = self.trigram(x) # batch_size, nb_filters, seq_len-2)\n",
    "        x_2 = self.pool(x_2) # (batch_size, nb_filters)\n",
    "        x_3 = self.fourgram(x) # batch_size, nb_filters, seq_len-3)\n",
    "        x_3 = self.pool(x_3) # (batch_size, nb_filters)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30522 # len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES = 2\n",
    "DROPOUT_RATE = 0.2\n",
    "NB_EPOCHS = 5\n",
    "\n",
    "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
    "            emb_dim=EMB_DIM,\n",
    "            nb_filters=NB_FILTERS,\n",
    "            FFN_units=FFN_UNITS,\n",
    "            nb_classes=NB_CLASSES,\n",
    "            dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NB_CLASSES == 2:\n",
    "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "else:\n",
    "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x20068aa9748>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"final_training/cp.ckpt\"\n",
    "Dcnn.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_clean\n",
    "def get_test_data(size: int = 1):\n",
    "    \"\"\"Generates a test dataset of the specified size\"\"\" \n",
    "    num_rows = len(X)\n",
    "    test_df = X.copy()\n",
    "\n",
    "    while num_rows < size:\n",
    "        test_df = test_df + test_df\n",
    "        num_rows = len(test_df)\n",
    "\n",
    "    return test_df[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________\n",
      "Inferencing Started...........\n",
      "running data prep and inference for 1 sentence(s)..\n",
      "length of predicted df 1\n",
      "1 ,        median       mean   std_dev   min_time   max_time  quantile_10  \\\n",
      "0   3918.000   4155.690  1085.287   3571.000  11405.000     3640.400   \n",
      "0 115055.500 122126.760 15629.216 110973.000 193813.000   112012.200   \n",
      "0 119173.500 126282.450 16252.551 114855.000 205218.000   115903.900   \n",
      "0 315451.500 325643.200 30677.964 305382.000 563341.000   310802.700   \n",
      "0 435285.500 451925.650 43038.795 422466.000 768559.000   428307.600   \n",
      "\n",
      "   quantile_90                   Flag  \n",
      "0     4278.700              Only Bert  \n",
      "0   144440.200          Prep w/o Bert  \n",
      "0   148467.300         Prep with Bert  \n",
      "0   350173.600         Inference Time  \n",
      "0   492700.400  Prep & Inf Time Total  \n",
      "running data prep and inference for 10 sentence(s)..\n",
      "length of predicted df 10\n",
      "10 ,       median      mean  std_dev  min_time  max_time  quantile_10  quantile_90  \\\n",
      "0  2020.550  1993.179   99.797  1843.400  2583.200     1886.550     2041.290   \n",
      "0 11388.550 11953.421 1211.386 10959.000 15450.500    11221.820    14414.930   \n",
      "0 13389.250 13946.600 1228.226 12851.900 18033.700    13126.270    16387.690   \n",
      "0 34156.150 34456.518 1386.960 32624.600 40316.800    33174.570    36433.570   \n",
      "0 47622.850 48403.118 2216.349 45962.700 57088.800    46450.730    51673.200   \n",
      "\n",
      "                    Flag  \n",
      "0              Only Bert  \n",
      "0          Prep w/o Bert  \n",
      "0         Prep with Bert  \n",
      "0         Inference Time  \n",
      "0  Prep & Inf Time Total  \n",
      "running data prep and inference for 100 sentence(s)..\n",
      "length of predicted df 100\n",
      "100 ,      median     mean  std_dev  min_time  max_time  quantile_10  quantile_90  \\\n",
      "0 2004.780 2041.954  173.866  1939.260  3275.920     1952.952     2143.847   \n",
      "0 1188.540 1242.792  165.214  1120.410  1985.090     1127.979     1420.513   \n",
      "0 3196.495 3284.747  262.450  3064.770  4490.060     3091.326     3472.590   \n",
      "0 5722.585 5804.699  486.013  5214.560  8301.470     5337.984     6214.996   \n",
      "0 8982.265 9089.446  595.185  8299.330 11839.590     8479.363     9764.371   \n",
      "\n",
      "                    Flag  \n",
      "0              Only Bert  \n",
      "0          Prep w/o Bert  \n",
      "0         Prep with Bert  \n",
      "0         Inference Time  \n",
      "0  Prep & Inf Time Total  \n",
      "running data prep and inference for 1000 sentence(s)..\n",
      "length of predicted df 1000\n",
      "1000 ,      median     mean  std_dev  min_time  max_time  quantile_10  quantile_90  \\\n",
      "0 2331.552 2414.625  410.121  1933.046  4007.505     2005.288     2974.894   \n",
      "0  130.346  153.994  190.195   115.894  2038.025      118.057      153.077   \n",
      "0 2466.294 2568.619  438.010  2056.168  4225.458     2140.223     3151.224   \n",
      "0 2907.656 2878.367  181.698  2559.186  3412.318     2645.456     3120.081   \n",
      "0 5358.193 5446.987  501.956  4703.432  7265.492     4938.416     6167.963   \n",
      "\n",
      "                    Flag  \n",
      "0              Only Bert  \n",
      "0          Prep w/o Bert  \n",
      "0         Prep with Bert  \n",
      "0         Inference Time  \n",
      "0  Prep & Inf Time Total  \n",
      "Summary........\n",
      "      median       mean   std_dev   min_time   max_time  quantile_10  \\\n",
      "0   3918.000   4155.690  1085.287   3571.000  11405.000     3640.400   \n",
      "0 115055.500 122126.760 15629.216 110973.000 193813.000   112012.200   \n",
      "0 119173.500 126282.450 16252.551 114855.000 205218.000   115903.900   \n",
      "0 315451.500 325643.200 30677.964 305382.000 563341.000   310802.700   \n",
      "0 435285.500 451925.650 43038.795 422466.000 768559.000   428307.600   \n",
      "0   2020.550   1993.179    99.797   1843.400   2583.200     1886.550   \n",
      "0  11388.550  11953.421  1211.386  10959.000  15450.500    11221.820   \n",
      "0  13389.250  13946.600  1228.226  12851.900  18033.700    13126.270   \n",
      "0  34156.150  34456.518  1386.960  32624.600  40316.800    33174.570   \n",
      "0  47622.850  48403.118  2216.349  45962.700  57088.800    46450.730   \n",
      "0   2004.780   2041.954   173.866   1939.260   3275.920     1952.952   \n",
      "0   1188.540   1242.792   165.214   1120.410   1985.090     1127.979   \n",
      "0   3196.495   3284.747   262.450   3064.770   4490.060     3091.326   \n",
      "0   5722.585   5804.699   486.013   5214.560   8301.470     5337.984   \n",
      "0   8982.265   9089.446   595.185   8299.330  11839.590     8479.363   \n",
      "0   2331.552   2414.625   410.121   1933.046   4007.505     2005.288   \n",
      "0    130.346    153.994   190.195    115.894   2038.025      118.057   \n",
      "0   2466.294   2568.619   438.010   2056.168   4225.458     2140.223   \n",
      "0   2907.656   2878.367   181.698   2559.186   3412.318     2645.456   \n",
      "0   5358.193   5446.987   501.956   4703.432   7265.492     4938.416   \n",
      "\n",
      "   quantile_90                   Flag  No_of_Observation  \n",
      "0     4278.700              Only Bert                  1  \n",
      "0   144440.200          Prep w/o Bert                  1  \n",
      "0   148467.300         Prep with Bert                  1  \n",
      "0   350173.600         Inference Time                  1  \n",
      "0   492700.400  Prep & Inf Time Total                  1  \n",
      "0     2041.290              Only Bert                 10  \n",
      "0    14414.930          Prep w/o Bert                 10  \n",
      "0    16387.690         Prep with Bert                 10  \n",
      "0    36433.570         Inference Time                 10  \n",
      "0    51673.200  Prep & Inf Time Total                 10  \n",
      "0     2143.847              Only Bert                100  \n",
      "0     1420.513          Prep w/o Bert                100  \n",
      "0     3472.590         Prep with Bert                100  \n",
      "0     6214.996         Inference Time                100  \n",
      "0     9764.371  Prep & Inf Time Total                100  \n",
      "0     2974.894              Only Bert               1000  \n",
      "0      153.077          Prep w/o Bert               1000  \n",
      "0     3151.224         Prep with Bert               1000  \n",
      "0     3120.081         Inference Time               1000  \n",
      "0     6167.963  Prep & Inf Time Total               1000  \n"
     ]
    }
   ],
   "source": [
    "def calculate_stats(time_list):\n",
    "    \"\"\"Calculate mean and standard deviation of a list\"\"\"\n",
    "    time_array = np.array(time_list)\n",
    "\n",
    "    median = np.median(time_array)\n",
    "    mean = np.mean(time_array)\n",
    "    std_dev = np.std(time_array)\n",
    "    max_time = np.amax(time_array)\n",
    "    min_time = np.amin(time_array)\n",
    "    quantile_10 = np.quantile(time_array, 0.1)\n",
    "    quantile_90 = np.quantile(time_array, 0.9)\n",
    "\n",
    "    basic_key = [\"median\",\"mean\",\"std_dev\",\"min_time\",\"max_time\",\"quantile_10\",\"quantile_90\"]\n",
    "    basic_value = [median,mean,std_dev,min_time,max_time,quantile_10,quantile_90]\n",
    "\n",
    "    dict_basic = dict(zip(basic_key, basic_value))\n",
    "    \n",
    "    return pd.DataFrame(dict_basic, index = [0])\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "NUM_LOOPS = 100\n",
    "\n",
    "def run_inference(num_observations:int = 1000):\n",
    "    \"\"\"Run xgboost for specified number of observations\"\"\"\n",
    "    # Load data\n",
    "    test_twt = get_test_data(num_observations)\n",
    "    num_rows = len(test_twt)\n",
    "    print(f\"running data prep and inference for {num_rows} sentence(s)..\")\n",
    "    \n",
    "    run_times = []\n",
    "    bert_times = []\n",
    "    prep_time_wo_berts = []\n",
    "    prep_time_alls = []\n",
    "    prep_inf_times = []\n",
    "    inference_times = []\n",
    "    \n",
    "    for _ in range(NUM_LOOPS):\n",
    "\n",
    "        st_tm_bert = timer()\n",
    "        data_inputs = [encode_sentence(sentence) for sentence in test_twt]    \n",
    "        end_tm_bert = timer()\n",
    "\n",
    "        data = bert_input_data(data_inputs)\n",
    "#         end_tm_prep = timer()\n",
    "        \n",
    "        start_time = timer()\n",
    "        pred_df = Dcnn.predict(data)\n",
    "        end_time = timer()\n",
    "\n",
    "        total_time = end_time - start_time\n",
    "        run_times.append(total_time*10e3)\n",
    "        \n",
    "        bert_time = (end_tm_bert-st_tm_bert)*(10e6)/num_rows\n",
    "        prep_time_wo_bert = (start_time-end_tm_bert)*(10e6)/num_rows\n",
    "        prep_time_all = (start_time-st_tm_bert)*(10e6)/num_rows\n",
    "        inference_time = total_time*(10e6)/num_rows\n",
    "        prep_inf_time = (end_time-st_tm_bert)*(10e6)/num_rows\n",
    "        \n",
    "        bert_times.append(bert_time)\n",
    "        prep_time_wo_berts.append(prep_time_wo_bert)\n",
    "        prep_time_alls.append(prep_time_all)\n",
    "        prep_inf_times.append(prep_inf_time)\n",
    "        inference_times.append(inference_time)\n",
    "        \n",
    "    print(\"length of predicted df\", len(pred_df))\n",
    "    \n",
    "    df1 = calculate_stats(bert_times)\n",
    "    df1[\"Flag\"] = \"Only Bert\"\n",
    "    df2 = calculate_stats(prep_time_wo_berts)\n",
    "    df2[\"Flag\"] = \"Prep w/o Bert\"\n",
    "    df3 = calculate_stats(prep_time_alls)\n",
    "    df3[\"Flag\"] = \"Prep with Bert\"\n",
    "    df4 = calculate_stats(prep_inf_times)\n",
    "    df4[\"Flag\"] = \"Prep & Inf Time Total\"\n",
    "    df5 = calculate_stats(inference_times)\n",
    "    df5[\"Flag\"] = \"Inference Time\"\n",
    "\n",
    "    dfs = pd.concat([df1,df2,df3,df5,df4])\n",
    "    \n",
    "    print(num_observations, \", \", dfs)\n",
    "    return dfs\n",
    "\n",
    "STATS = '#, median, mean, std_dev, min_time, max_time, quantile_10, quantile_90'\n",
    "\n",
    "print(\"_______________________________________________________________\")\n",
    "print(\"Inferencing Started...........\")\n",
    "if __name__=='__main__':\n",
    "    ob_ct = 1  # Start with a single observation\n",
    "    logging.info(STATS)\n",
    "    temp_df = pd.DataFrame()\n",
    "    while ob_ct <= 1000:\n",
    "        temp = run_inference(ob_ct)\n",
    "        temp[\"No_of_Observation\"] = ob_ct\n",
    "        temp_df = temp_df.append(temp)\n",
    "        ob_ct *= 10\n",
    "    print(\"Summary........\")\n",
    "    print(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
